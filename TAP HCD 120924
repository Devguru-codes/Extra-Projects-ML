{"cells":[{"cell_type":"markdown","metadata":{"id":"r95FU-RffZ57"},"source":["# Import libraries"]},{"cell_type":"code","execution_count":1,"metadata":{"id":"93vny2MJfZ58","executionInfo":{"status":"ok","timestamp":1737678100579,"user_tz":-330,"elapsed":12881,"user":{"displayName":"akshat shukla","userId":"01979925258072508501"}}},"outputs":[],"source":["import os\n","import numpy as np\n","import pandas as pd\n","import pickle\n","import matplotlib.pyplot as plt\n","import matplotlib.image as mpimg\n","import cv2\n","import tensorflow as tf\n","\n","from sklearn.model_selection import train_test_split\n","from sklearn.utils.class_weight import compute_class_weight\n","from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay, classification_report\n","from sklearn.utils import class_weight\n","\n","from itertools import cycle\n","\n","from tensorflow.keras.models import Sequential\n","from tensorflow.keras.layers import (\n","    Layer, Dense, Conv2D, Flatten, MaxPooling2D, Dropout, BatchNormalization,\n","    GlobalAveragePooling2D, GlobalMaxPooling2D, Reshape, Multiply, Concatenate, LeakyReLU\n",")\n","from tensorflow.keras.optimizers import Adam\n","from tensorflow.keras.preprocessing.image import ImageDataGenerator\n","from tensorflow.keras.utils import to_categorical\n","from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint, Callback, ReduceLROnPlateau\n","from tensorflow.keras.metrics import AUC\n","from tensorflow.keras.regularizers import l2\n","from tensorflow.keras.saving import register_keras_serializable\n"]},{"cell_type":"markdown","metadata":{"id":"4GeYLoLJfZ5-"},"source":["# Set directories, load csv"]},{"cell_type":"code","execution_count":2,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":356},"id":"84QQMAI4fZ5_","executionInfo":{"status":"error","timestamp":1737678100586,"user_tz":-330,"elapsed":22,"user":{"displayName":"akshat shukla","userId":"01979925258072508501"}},"outputId":"bffd6e93-628b-44ce-8dd6-76e8f9a42f75"},"outputs":[{"output_type":"error","ename":"FileNotFoundError","evalue":"[Errno 2] No such file or directory: '/kaggle/input/histopathologic-cancer-detection/train_labels.csv'","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-2-0ac04141e63b>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m# Read labels\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mfull_df\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabel_csv\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0mfull_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'id'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfull_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'id'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'.tif'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0mfull_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'label'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfull_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'label'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[1;32m   1024\u001b[0m     \u001b[0mkwds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwds_defaults\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1025\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1026\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1027\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1028\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    618\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    619\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 620\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    621\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    622\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m   1618\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1619\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandles\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mIOHandles\u001b[0m \u001b[0;34m|\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1620\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1621\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1622\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, f, engine)\u001b[0m\n\u001b[1;32m   1878\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;34m\"b\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1879\u001b[0m                     \u001b[0mmode\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34m\"b\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1880\u001b[0;31m             self.handles = get_handle(\n\u001b[0m\u001b[1;32m   1881\u001b[0m                 \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1882\u001b[0m                 \u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/io/common.py\u001b[0m in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    871\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoding\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;34m\"b\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    872\u001b[0m             \u001b[0;31m# Encoding\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 873\u001b[0;31m             handle = open(\n\u001b[0m\u001b[1;32m    874\u001b[0m                 \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    875\u001b[0m                 \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/kaggle/input/histopathologic-cancer-detection/train_labels.csv'"]}],"source":["# Paths to data\n","train_images = '/kaggle/input/histopathologic-cancer-detection/train/'\n","label_csv = '/kaggle/input/histopathologic-cancer-detection/train_labels.csv'\n","\n","# Read labels\n","full_df = pd.read_csv(label_csv)\n","full_df['id'] = full_df['id'] + '.tif'\n","full_df['label'] = full_df['label'].astype(str)\n","\n","# Filtering function\n","def filter_images(image_dir, image_ids, black_thresh=0.95, white_thresh=0.95):\n","    valid_ids = []\n","\n","    for img_id in image_ids:\n","        img_path = os.path.join(image_dir, img_id)\n","        img = cv2.imread(img_path, cv2.IMREAD_GRAYSCALE)\n","\n","        if img is None:\n","            continue  # Skip unreadable images\n","\n","        # Normalize pixel values to [0, 1]\n","        img = img / 255.0\n","\n","        # Calculate black and white pixel ratios\n","        black_ratio = np.sum(img < 0.1) / img.size\n","        white_ratio = np.sum(img > 0.9) / img.size\n","\n","        # Keep images that are NOT mostly black or white\n","        if black_ratio < black_thresh and white_ratio < white_thresh:\n","            valid_ids.append(img_id)\n","\n","    return valid_ids\n","\n","# Filter the images\n","valid_image_ids = filter_images(train_images, full_df['id'].tolist())\n","print(f\"Number of valid images: {len(valid_image_ids)}\")\n","\n","# Update full_df to include only valid images\n","filtered_df = full_df[full_df['id'].isin(valid_image_ids)].reset_index(drop=True)\n","print(f\"Updated dataframe shape: {filtered_df.shape}\")\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"_C3sFAp_fZ6A","executionInfo":{"status":"aborted","timestamp":1737678100586,"user_tz":-330,"elapsed":19,"user":{"displayName":"akshat shukla","userId":"01979925258072508501"}}},"outputs":[],"source":["filtered_df.head()"]},{"cell_type":"markdown","metadata":{"id":"Yrt-Ruj9fZ6A"},"source":["# Determine label frequency"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"IYUWgWhSfZ6B","executionInfo":{"status":"aborted","timestamp":1737678100586,"user_tz":-330,"elapsed":18,"user":{"displayName":"akshat shukla","userId":"01979925258072508501"}}},"outputs":[],"source":["# Calculate frequency distribution\n","frequency_distribution = (filtered_df.label.value_counts() / len(filtered_df)).to_frame()\n","\n","# Plotting the frequency distribution as a bar chart\n","plt.figure(figsize=(6, 4))\n","colors = ['lightgreen', 'lightcoral']  # light green for benign, light red for malignant\n","\n","# Plotting bar chart with specified colors\n","frequency_distribution.iloc[:, 0].plot(kind='bar', color=colors)\n","\n","# Customizing chart\n","plt.title('Frequency Distribution of Labels')\n","plt.xlabel('Label')\n","plt.ylabel('Frequency')\n","plt.xticks([0, 1], ['Benign', 'Malignant'], rotation=0)\n","\n","# Show the plot\n","plt.show()"]},{"cell_type":"markdown","metadata":{"id":"7YPrpyYCfZ6C"},"source":["# Sample images"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ABWggbSdfZ6C","executionInfo":{"status":"aborted","timestamp":1737678100586,"user_tz":-330,"elapsed":18,"user":{"displayName":"akshat shukla","userId":"01979925258072508501"}}},"outputs":[],"source":["# Sample 16 images and labels from the training set\n","sample_images = filtered_df.sample(16)\n","\n","# Set up the figure and axes\n","fig, axes = plt.subplots(4, 4, figsize=(6, 6))\n","fig.tight_layout(pad=1.0)\n","\n","# Loop through the images and display each one with its label\n","for i, ax in enumerate(axes.flat):\n","    # Get the filename and label for each sample\n","    id = sample_images.iloc[i]['id']\n","    label = sample_images.iloc[i]['label']\n","\n","    # Load the image from file\n","    img = mpimg.imread(os.path.join(train_images, id))\n","\n","    # Display the image\n","    ax.imshow(img, cmap='gray')\n","    ax.set_title(f\"Label: {label}\")\n","    ax.axis('off')\n","\n","plt.show()"]},{"cell_type":"markdown","metadata":{"id":"OMPOl2KZfZ6D"},"source":["# Split into train and validation dataframes"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ipE9W6gIfZ6D","executionInfo":{"status":"aborted","timestamp":1737678100587,"user_tz":-330,"elapsed":19,"user":{"displayName":"akshat shukla","userId":"01979925258072508501"}}},"outputs":[],"source":["# Split the data into train_df and valid_df with stratified sampling\n","train_df, valid_df = train_test_split(\n","    filtered_df,\n","    test_size=0.2,               # 20% for validation\n","    stratify=filtered_df['label'],     # Stratify by the label column to preserve proportions\n","    random_state=42              # Set random seed for reproducibility\n",")\n","\n","# Display the size of each dataset to confirm the split\n","print(f\"Training set size: {len(train_df)}\")\n","print(f\"Validation set size: {len(valid_df)}\")"]},{"cell_type":"markdown","metadata":{"id":"__0zo3mQfZ6E"},"source":["# Ensure no data leakage between train and validation df"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"gEx3V4sPfZ6E","executionInfo":{"status":"aborted","timestamp":1737678100587,"user_tz":-330,"elapsed":18,"user":{"displayName":"akshat shukla","userId":"01979925258072508501"}}},"outputs":[],"source":["print(len(set(train_df['id']).intersection(set(valid_df['id']))) == 0)  # Should return True"]},{"cell_type":"markdown","metadata":{"id":"RindrOgRfZ6E"},"source":["# Ensure even label distribution between train and validation images"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"zurxO30efZ6E","executionInfo":{"status":"aborted","timestamp":1737678100587,"user_tz":-330,"elapsed":18,"user":{"displayName":"akshat shukla","userId":"01979925258072508501"}}},"outputs":[],"source":["# Calculate the frequencies for training and validation sets\n","train_frequency = (train_df.label.value_counts() / len(train_df)).to_frame('train_frequency')\n","valid_frequency = (valid_df.label.value_counts() / len(valid_df)).to_frame('valid_frequency')\n","\n","# Merging the two dataframes to plot them side by side\n","frequency_df = pd.concat([train_frequency, valid_frequency], axis=1)\n","\n","# Plotting the side-by-side bar chart\n","plt.figure(figsize=(8, 5))\n","frequency_df.plot(kind='bar', color=['lightgreen', 'lightcoral'], width=0.8)\n","\n","# Customizing chart\n","plt.title('Frequency Distribution of Labels in Train and Validation Sets')\n","plt.xlabel('Label')\n","plt.ylabel('Frequency')\n","plt.xticks([0, 1], ['Benign', 'Malignant'], rotation=0)\n","plt.legend(['Train Frequency', 'Validation Frequency'], loc='upper right')\n","\n","# Show the plot\n","plt.show()"]},{"cell_type":"markdown","metadata":{"id":"1vk4f6hyfZ6F"},"source":["# Create data generator and loaders"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"IWN-hHfpfZ6F","executionInfo":{"status":"aborted","timestamp":1737678100587,"user_tz":-330,"elapsed":18,"user":{"displayName":"akshat shukla","userId":"01979925258072508501"}}},"outputs":[],"source":["# Set batch size\n","BATCH_SIZE = 32\n","\n","# Combined data generator with augmentations\n","train_datagen = ImageDataGenerator(\n","    rescale=1/255,                # Normalize pixel values to [0, 1]\n","    rotation_range=15,            # Rotate images by up to 15 degrees\n","    width_shift_range=0.4,        # Horizontal shift (up to 40%)\n","    height_shift_range=0.4,       # Vertical shift (up to 40%)\n","    horizontal_flip=True,         # Flip images horizontally\n","    zoom_range=0.2,               # Zoom in/out slightly\n","    fill_mode='reflect'           # Fill mode to handle shifts (options: 'nearest', 'constant', 'reflect', 'wrap')\n",")\n","\n","# Flow the entire training dataframe\n","train_loader = train_datagen.flow_from_dataframe(\n","    dataframe=train_df,           # Full training dataframe\n","    directory=train_images,       # Directory with images\n","    x_col='id',                   # Column with image filenames\n","    y_col='label',                # Column with labels (0 or 1)\n","    class_mode='binary',          # Binary classification\n","    target_size=(96, 96),         # Resize images to 96x96\n","    batch_size=BATCH_SIZE,        # Batch size\n","    shuffle=True                  # Shuffle images during training\n",")\n","\n","# Validation data generator (no augmentations)\n","valid_datagen = ImageDataGenerator(rescale=1/255)\n","\n","valid_loader = valid_datagen.flow_from_dataframe(\n","    dataframe=valid_df,           # Validation dataframe\n","    directory=train_images,       # Directory with images\n","    x_col='id',\n","    y_col='label',\n","    class_mode='binary',\n","    target_size=(96, 96),\n","    batch_size=BATCH_SIZE,\n","    shuffle=False                 # No shuffling for validation\n",")\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"q_AvPE6-fZ6F","executionInfo":{"status":"aborted","timestamp":1737678100587,"user_tz":-330,"elapsed":18,"user":{"displayName":"akshat shukla","userId":"01979925258072508501"}}},"outputs":[],"source":["print(valid_df.head())\n","print(f\"Total validation samples: {len(valid_df)}\")\n"]},{"cell_type":"markdown","metadata":{"id":"Xj-ieASxfZ6F"},"source":["# Visualize Augmentation of Train Images"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"aQd9QFxwfZ6F","executionInfo":{"status":"aborted","timestamp":1737678100587,"user_tz":-330,"elapsed":18,"user":{"displayName":"akshat shukla","userId":"01979925258072508501"}}},"outputs":[],"source":["# Fetch a batch of images and labels from the generator\n","augmented_images, labels = next(train_loader)\n","\n","# Plot 9 images from the batch\n","plt.figure(figsize=(10, 10))\n","for i in range(9):\n","    plt.subplot(3, 3, i+1)\n","    plt.imshow(augmented_images[i])  # Display each image\n","    plt.axis('off')\n","    plt.title(f\"Label: {int(labels[i])}\")  # Show label ID as title\n","\n","plt.tight_layout()\n","plt.show()"]},{"cell_type":"markdown","metadata":{"id":"MqLGdFGkfZ6G"},"source":["# Determine number of steps"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"XdyQq0hjfZ6G","executionInfo":{"status":"aborted","timestamp":1737678100587,"user_tz":-330,"elapsed":18,"user":{"displayName":"akshat shukla","userId":"01979925258072508501"}}},"outputs":[],"source":["TR_STEPS = len(train_loader)\n","VA_STEPS = len(valid_loader)\n","\n","print(TR_STEPS)\n","print(VA_STEPS)"]},{"cell_type":"markdown","metadata":{"id":"6t4SQjNNfZ6H"},"source":["# Define CBAM class and define model"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"4b4QO6vwfZ6H","executionInfo":{"status":"aborted","timestamp":1737678100587,"user_tz":-330,"elapsed":18,"user":{"displayName":"akshat shukla","userId":"01979925258072508501"}}},"outputs":[],"source":["@register_keras_serializable()\n","class CBAM(Layer):\n","    def __init__(self, channels, reduction_ratio=16, **kwargs):\n","        super(CBAM, self).__init__(**kwargs)\n","        self.channels = channels\n","        self.reduction_ratio = reduction_ratio\n","\n","        # Channel attention layers\n","        self.global_avg_pool = GlobalAveragePooling2D()\n","        self.global_max_pool = GlobalMaxPooling2D()\n","        self.fc1 = Dense(channels // reduction_ratio, activation='relu')\n","        self.fc2 = Dense(channels, activation='sigmoid')\n","\n","        # Spatial attention layers\n","        self.conv = Conv2D(1, kernel_size=7, padding='same', activation='sigmoid')\n","\n","    def build(self, input_shape):\n","        # Ensure variables are built once\n","        self.reshape_layer = Reshape((1, 1, self.channels))\n","        self.concat_layer = Concatenate(axis=-1)\n","        self.multiply_layer = Multiply()\n","\n","    def call(self, inputs):\n","        # Channel Attention\n","        avg_out = self.global_avg_pool(inputs)\n","        max_out = self.global_max_pool(inputs)\n","        avg_out = self.fc2(self.fc1(self.reshape_layer(avg_out)))\n","        max_out = self.fc2(self.fc1(self.reshape_layer(max_out)))\n","        channel_attention = self.multiply_layer([inputs, avg_out + max_out])\n","\n","        # Spatial Attention\n","        avg_pool = tf.reduce_mean(channel_attention, axis=-1, keepdims=True)\n","        max_pool = tf.reduce_max(channel_attention, axis=-1, keepdims=True)\n","        spatial_attention = self.conv(self.concat_layer([avg_pool, max_pool]))\n","        return self.multiply_layer([channel_attention, spatial_attention])\n","\n","    def get_config(self):\n","        config = super(CBAM, self).get_config()\n","        config.update({\n","            \"channels\": self.channels,\n","            \"reduction_ratio\": self.reduction_ratio\n","        })\n","        return config\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"lNT88S42fZ6K","executionInfo":{"status":"aborted","timestamp":1737678100587,"user_tz":-330,"elapsed":17,"user":{"displayName":"akshat shukla","userId":"01979925258072508501"}}},"outputs":[],"source":["np.random.seed(1)\n","tf.random.set_seed(1)\n","\n","def create_cbam_cnn():\n","    cnn = Sequential([\n","        # First convolutional block\n","        Conv2D(32, (3, 3), padding='same', input_shape=(96, 96, 3)),\n","        BatchNormalization(),\n","        LeakyReLU(),\n","        MaxPooling2D(pool_size=(2, 2)),\n","        Dropout(0.25),\n","\n","        # Second convolutional block\n","        Conv2D(64, (3, 3), padding='same'),\n","        BatchNormalization(),\n","        LeakyReLU(),\n","        CBAM(64),  # CBAM Block\n","        MaxPooling2D(pool_size=(2, 2)),\n","        Dropout(0.25),\n","\n","        # Third convolutional block\n","        Conv2D(128, (3, 3), padding='same'),\n","        BatchNormalization(),\n","        LeakyReLU(),\n","        MaxPooling2D(pool_size=(2, 2)),\n","        Dropout(0.3),\n","\n","        # Fourth convolutional block\n","        Conv2D(256, (3, 3), padding='same'),\n","        BatchNormalization(),\n","        LeakyReLU(),\n","        CBAM(256),  # CBAM Block\n","        MaxPooling2D(pool_size=(2, 2)),\n","        Dropout(0.3),\n","\n","        # Global Average Pooling instead of Flatten\n","        GlobalAveragePooling2D(),\n","\n","        # Dense layers with L2 regularization\n","        Dense(128, activation='relu', kernel_regularizer=tf.keras.regularizers.l2(0.001)),\n","        BatchNormalization(),\n","        Dropout(0.5),\n","\n","        Dense(64, activation='relu', kernel_regularizer=tf.keras.regularizers.l2(0.001)),\n","        BatchNormalization(),\n","        Dropout(0.5),\n","\n","        # Output layer for binary classification\n","        Dense(1, activation='sigmoid')  # Adjusted for binary classification\n","    ])\n","    return cnn\n","\n","cnn = create_cbam_cnn()\n","cnn.summary()\n"]},{"cell_type":"markdown","metadata":{"id":"MEYPDLGvfZ6K"},"source":["# Define optimizer, assign class weighting and compile model"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"1UscbJXmfZ6L","executionInfo":{"status":"aborted","timestamp":1737678100588,"user_tz":-330,"elapsed":18,"user":{"displayName":"akshat shukla","userId":"01979925258072508501"}}},"outputs":[],"source":["# Define the optimizer\n","learning_rate = 0.0001  # You can adjust this based on your model's performance\n","optimizer = Adam(learning_rate=learning_rate)\n","\n","# Compile the model with the optimizer, a loss function, and metrics\n","cnn.compile(optimizer=optimizer,\n","            loss='binary_crossentropy',\n","            metrics=[AUC(name='auc')])   # Track accuracy as the performance metric\n"]},{"cell_type":"markdown","metadata":{"id":"mE6xREyafZ6L"},"source":["# Determine Class Weights"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"h-Nde7JHfZ6L","executionInfo":{"status":"aborted","timestamp":1737678100588,"user_tz":-330,"elapsed":18,"user":{"displayName":"akshat shukla","userId":"01979925258072508501"}}},"outputs":[],"source":["# Get class labels and calculate weights\n","class_labels = train_df['label']  # Replace with actual training labels\n","class_weights = class_weight.compute_class_weight(\n","    class_weight='balanced',\n","    classes=np.unique(class_labels),\n","    y=class_labels\n",")\n","\n","# Convert to a dictionary\n","class_weights_dict = {i: weight for i, weight in enumerate(class_weights)}\n","print(\"Class Weights:\", class_weights_dict)"]},{"cell_type":"markdown","metadata":{"id":"jI6RFqc8fZ6L"},"source":["# Train model"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"26dU7rW0fZ6M","executionInfo":{"status":"aborted","timestamp":1737678100588,"user_tz":-330,"elapsed":18,"user":{"displayName":"akshat shukla","userId":"01979925258072508501"}}},"outputs":[],"source":["# Callbacks\n","early_stop = EarlyStopping(monitor='val_auc', patience=5, restore_best_weights=True)\n","lr_scheduler = ReduceLROnPlateau(monitor='val_auc', factor=0.5, patience=3, verbose=1)\n","model_checkpoint = ModelCheckpoint(\"best_cbam_model.keras\", save_best_only=True, monitor=\"val_auc\")\n","\n","# Specify the number of steps per epoch for the train dataframe\n","steps_per_epoch = len(train_loader)  # Single generator for train dataframe\n","\n","# Train the model\n","history = cnn.fit(\n","    train_loader,\n","    validation_data=valid_loader,\n","    epochs=30,\n","    callbacks=[early_stop, lr_scheduler, model_checkpoint],\n","    class_weight=class_weights_dict,\n","    verbose=1\n",")\n","\n"]},{"cell_type":"markdown","metadata":{"id":"dCGI9v14fZ6M"},"source":["# Plot results"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"YxBv2BblfZ6M","executionInfo":{"status":"aborted","timestamp":1737678100588,"user_tz":-330,"elapsed":18,"user":{"displayName":"akshat shukla","userId":"01979925258072508501"}}},"outputs":[],"source":["# Plot the training and validation accuracy and loss curves\n","def plot_training_curves(history):\n","    # Get training and validation metrics\n","    auc = history.history['auc']\n","    val_auc = history.history['val_auc']\n","    loss = history.history['loss']\n","    val_loss = history.history['val_loss']\n","    epochs_range = range(len(auc))\n","\n","    plt.figure(figsize=(12, 6))\n","\n","    # Plot AUC\n","    plt.subplot(1, 2, 1)\n","    plt.plot(epochs_range, auc, label='Training AUC')\n","    plt.plot(epochs_range, val_auc, label='Validation AUC')\n","    plt.xlabel('Epochs')\n","    plt.ylabel('AUC')\n","    plt.legend(loc='lower right')\n","    plt.title('Training and Validation AUC')\n","\n","    # Plot Loss\n","    plt.subplot(1, 2, 2)\n","    plt.plot(epochs_range, loss, label='Training Loss')\n","    plt.plot(epochs_range, val_loss, label='Validation Loss')\n","    plt.xlabel('Epochs')\n","    plt.ylabel('Loss')\n","    plt.legend(loc='upper right')\n","    plt.title('Training and Validation Loss')\n","\n","    plt.show()\n","\n","# Call the function to display the curves\n","plot_training_curves(history)"]},{"cell_type":"markdown","metadata":{"id":"25aOJKggfZ6N"},"source":["# Confusion Matrix and Classification Report"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"eK56aXXEfZ6N","executionInfo":{"status":"aborted","timestamp":1737678100588,"user_tz":-330,"elapsed":18,"user":{"displayName":"akshat shukla","userId":"01979925258072508501"}}},"outputs":[],"source":["# Define class names for labels\n","class_names = [\"Benign\", \"Malignant\"]\n","\n","# Get true labels from validation set\n","y_true = valid_loader.labels  # True labels from validation generator\n","\n","# Predict probabilities for the validation set\n","y_pred_prob = cnn.predict(valid_loader)  # Predicted probabilities\n","\n","# Convert probabilities to binary class predictions\n","y_pred = (y_pred_prob > 0.5).astype(int).flatten()  # Binary classification threshold\n","\n","# Generate the confusion matrix\n","conf_matrix = confusion_matrix(y_true, y_pred)\n","\n","# Display the confusion matrix\n","fig, ax = plt.subplots(figsize=(8, 8))\n","disp = ConfusionMatrixDisplay(confusion_matrix=conf_matrix, display_labels=class_names)\n","disp.plot(cmap=plt.cm.Blues, ax=ax, colorbar=True)\n","\n","plt.title(\"Confusion Matrix\")\n","plt.show()\n","\n","# Generate the precision-recall report\n","print(\"Classification Report:\")\n","report = classification_report(y_true, y_pred, target_names=class_names)\n","print(report)\n"]},{"cell_type":"markdown","metadata":{"id":"4h9-cZtefZ6N"},"source":["# Save Model"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Jy-O9K4qfZ6N","executionInfo":{"status":"aborted","timestamp":1737678100588,"user_tz":-330,"elapsed":18,"user":{"displayName":"akshat shukla","userId":"01979925258072508501"}}},"outputs":[],"source":["cnn.save('/kaggle/working/120924v2.keras')\n","pickle.dump(history, open(f'cnn_history_120724.pkl', 'wb'))"]}],"metadata":{"colab":{"provenance":[{"file_id":"https://storage.googleapis.com/kaggle-colab-exported-notebooks/tap-hcd-120924-ab76324b-8d76-4c3d-bb83-a679ebc061ca.ipynb?X-Goog-Algorithm=GOOG4-RSA-SHA256&X-Goog-Credential=gcp-kaggle-com%40kaggle-161607.iam.gserviceaccount.com/20241225/auto/storage/goog4_request&X-Goog-Date=20241225T154409Z&X-Goog-Expires=259200&X-Goog-SignedHeaders=host&X-Goog-Signature=50e1181f864d326df3d571541fa99ca86e66c3a687bed62dbe554a118b1a5d1e34df534a240bd16e94718c37cb819746dcb8c9dfe10981d37bd15b0cecc10d4af33063c41db0da578abeaeb8e36038fc62f02f0dd16519e5a0561f296ef80ff9f6eb1f68468f8e99bb0674cf4fc9cffb0105472ee997f52d4a103d40ed3276eaa62c2b28540ac3f4c84b84c6c58513d17d8c7e19989b8d5fed7192f00d673a9d8854c36a928143897473d1807df08102f344b95f13eef7dee0ac98fc4c9fa48583c1675318df6a3f2ba0b51367f4ca1af5a15800948a924ed6da75f6a484d1eb18a3e2ca8a20b307182f8d73128128ffede8c7c77b6ac19e3dcc7e8b9351b152","timestamp":1735141473075}],"gpuType":"T4"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"databundleVersionId":862157,"sourceId":11848,"sourceType":"competition"}],"dockerImageVersionId":30787,"isGpuEnabled":true,"isInternetEnabled":true,"language":"python","sourceType":"notebook"},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.14"},"accelerator":"GPU"},"nbformat":4,"nbformat_minor":0}