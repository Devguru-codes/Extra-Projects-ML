{"cells":[{"metadata":{"id":"Ym0MAc6esD80"},"cell_type":"markdown","source":["# Introduction\n","This notebook provides solution to [Histopathologic Cancer Detection](https://www.kaggle.com/c/histopathologic-cancer-detection/overview) challenge on Kaggle. This is a perfect Computer Vision problem where we are tasked with the detection of cancer by identifying metastatic tissue in histopathologic scans of lymph nodes using Deep Learning.\n","\n","![Header Image](https://storage.googleapis.com/kaggle-competitions/kaggle/11848/logos/header.png?t=2018-11-15-01-52-19)\n","\n","\n","### 1. Understanding the Problem:\n","Our goal is to create an algorithm to identify metastatic cancer in small image patches taken from larger digital pathology scans.\n","\n","Obviously I don't know biology to understand this problem right away, here is what I found online about histopathology.\n","\n","> Histopathology is the study of the signs of the disease using the microscopic examination of a biopsy or surgical specimen that is processed and fixed onto glass slides. To visualize different components of the tissue under a microscope, the sections are dyed with one or more stains.\n","\n","### Motivation:\n","Lymph nodes are small glands that filter the fluid in the lymphatic system and they are the first place a breast cancer is likely to spread. Histological assessment of lymph node metastases is part of determining the stage of breast cancer in TNM classification which is a globally recognized standard for classifying the extent of spread of cancer.\n","> **The diagnostic procedure for pathologists is tedious and time-consuming as a large area of tissue has to be examined and small metastases can be easily missed.**\n","\n","That makes using Machine Learning a great choice both in terms of accuracy and ease of usability. It could bring a great change altogether.\n","\n","### 2. Understanding the Data:\n","\n","**The train data we have here contains 220,025 images and the test set contains 57,468 images.**\n","\n","It is important to take into account that this data is only a subset of the original [PCam dataset](https://github.com/basveeling/pcam) which in the end is derived from the [Camelyon16 Challenge dataset](https://camelyon16.grand-challenge.org/Data/), which contains 400 H&E stained whole slide images of sentinel lymph node sections that were acquired and digitized at 2 different centers using a 40x objective. The PCam's dataset including this one uses 10x undersampling to increase the field of view, which gives the resultant pixel resolution of 2.43 microns.\n","\n","Here's what Kaggle says,\n","\n","> The original PCam dataset contains duplicate images due to its probabilistic sampling, however, the version presented on Kaggle does not contain duplicates. We have otherwise maintained the same data and splits as the PCam benchmark.\n","\n","Our training data has a class distribution of 60:40 negative and positive samples which is not bad.\n","\n","I also found that these data were obtained as a result of routine clinical practices and similar to how a trained pathologist would examine similar images for identifying metastases. However, some relevant information about the surroundings might be left out with these small-sized image samples (I guess).\n","\n","### 3. Understanding the Images\n"," > You are predicting the labels for the images in the test folder. A positive label indicates that the center 32x32px region of a patch contains at least one pixel of tumor tissue. Tumor tissue in the outer region of the patch does not influence the label. This outer region is provided to enable fully-convolutional models that do not use zero-padding, to ensure consistent behavior when applied to a whole-slide image.\n","\n","This from the competition's description means that the centers of the images are the ones that really matter.\n","\n","As you might already know, **this is a binary classification problem**.\n","\n","### 4. Understanding the Evaluation Metric\n","The evaluation metric is the **Area Under ROC Curve** which is also called **AU-ROC/AOC Curve**. It is one of the most important evaluation metrics for checking any classification modelâ€™s performance.\n","\n","AUC - ROC curve is a performance measurement for classification problem at various thresholds settings. ROC is a probability curve and AUC represents degree or measure of separability. **It tells how much model is capable of distinguishing between classes.** Higher the AUC, better the model is at predicting 0s as 0s and 1s as 1s. By analogy, higher the AUC (close to 1), better the model is at distinguishing between patients with disease and no disease. The curve is plotted with True Positive Rates Vs the False Positive Rates along the x and y axes respectively.\n","\n","\n","ROC                        |  AUC\n",":-------------------------:|:-------------------------:\n","![ROC Curve](http://gim.unmc.edu/dxtests/roccomp.jpg)  |   ![AUC Curve](https://i.ibb.co/mBKh6ZB/roc.pnghttps://i.ibb.co/mBKh6ZB/roc.png)\n"]},{"source":["import numpy as np # linear algebra\n","import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n","\n","import os\n","# Change the base_dir to the correct path for your environment.\n","# If you are running this code locally, you will need to replace '../input'\n","# with the actual path to your data directory.\n","base_dir = '../input'\n","print(os.listdir(base_dir))\n","\n","# Matplotlib for visualization\n","import matplotlib.pyplot as plt\n","plt.style.use(\"ggplot\")\n","\n","# OpenCV Image Library\n","import cv2\n","\n","# Import PyTorch\n","import torchvision.transforms as transforms\n","from torch.utils.data.sampler import SubsetRandomSampler\n","import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","from torch.utils.data import TensorDataset, DataLoader, Dataset\n","import torchvision\n","import torch.optim as optim\n","\n","# Import useful sklearn functions\n","import sklearn\n","from sklearn.metrics import roc_auc_score, accuracy_score\n","from PIL import Image"],"cell_type":"code","metadata":{"id":"STV9ecQStArp","executionInfo":{"status":"error","timestamp":1737678395282,"user_tz":-330,"elapsed":742,"user":{"displayName":"akshat shukla","userId":"01979925258072508501"}},"outputId":"8b985d24-7ac1-4948-c22f-1f94be82b517","colab":{"base_uri":"https://localhost:8080/","height":211}},"execution_count":7,"outputs":[{"output_type":"error","ename":"FileNotFoundError","evalue":"[Errno 2] No such file or directory: '../input'","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-7-45c7b14dabae>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;31m# with the actual path to your data directory.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0mbase_dir\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'../input'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlistdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbase_dir\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;31m# Matplotlib for visualization\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '../input'"]}]},{"metadata":{"id":"yPTiAO-rsD86"},"cell_type":"markdown","source":["# Loading Data and EDA\n","Having a look at the data, just like any other image classification problem we have a csv file with image ids and labels. The directories train, test contain the actual images."]},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":true,"id":"6fxIUYIwsD86","colab":{"base_uri":"https://localhost:8080/","height":321},"executionInfo":{"status":"error","timestamp":1737678325204,"user_tz":-330,"elapsed":23,"user":{"displayName":"akshat shukla","userId":"01979925258072508501"}},"outputId":"8c2bc2f9-11e7-4db4-af68-3ad46810c8bd"},"cell_type":"code","source":["full_train_df = pd.read_csv(\"../input/train_labels.csv\")\n","full_train_df.head()"],"execution_count":2,"outputs":[{"output_type":"error","ename":"FileNotFoundError","evalue":"[Errno 2] No such file or directory: '../input/train_labels.csv'","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-2-8b84a5dcc301>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mfull_train_df\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"../input/train_labels.csv\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mfull_train_df\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[1;32m   1024\u001b[0m     \u001b[0mkwds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwds_defaults\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1025\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1026\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1027\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1028\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    618\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    619\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 620\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    621\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    622\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m   1618\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1619\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandles\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mIOHandles\u001b[0m \u001b[0;34m|\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1620\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1621\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1622\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, f, engine)\u001b[0m\n\u001b[1;32m   1878\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;34m\"b\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1879\u001b[0m                     \u001b[0mmode\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34m\"b\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1880\u001b[0;31m             self.handles = get_handle(\n\u001b[0m\u001b[1;32m   1881\u001b[0m                 \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1882\u001b[0m                 \u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/io/common.py\u001b[0m in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    871\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoding\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;34m\"b\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    872\u001b[0m             \u001b[0;31m# Encoding\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 873\u001b[0;31m             handle = open(\n\u001b[0m\u001b[1;32m    874\u001b[0m                 \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    875\u001b[0m                 \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '../input/train_labels.csv'"]}]},{"metadata":{"trusted":true,"id":"vtaiEVRmsD87","executionInfo":{"status":"aborted","timestamp":1737678325204,"user_tz":-330,"elapsed":22,"user":{"displayName":"akshat shukla","userId":"01979925258072508501"}}},"cell_type":"code","source":["print(\"Train Size: {}\".format(len(os.listdir('../input/train/'))))\n","print(\"Test Size: {}\".format(len(os.listdir('../input/test/'))))"],"execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"id":"mRszVlbIsD87","executionInfo":{"status":"aborted","timestamp":1737678325205,"user_tz":-330,"elapsed":22,"user":{"displayName":"akshat shukla","userId":"01979925258072508501"}}},"cell_type":"code","source":["labels_count = full_train_df.label.value_counts()\n","\n","%matplotlib inline\n","plt.pie(labels_count, labels=['No Cancer', 'Cancer'], startangle=180,\n","        autopct='%1.1f', colors=['#00ff99','#FF96A7'], shadow=True)\n","plt.figure(figsize=(16,16))\n","plt.show()"],"execution_count":null,"outputs":[]},{"metadata":{"id":"jOEZE2WXsD87"},"cell_type":"markdown","source":["# Visualizing Images\n","Classifying metastases is probably not an easy task for a trained pathologist and extremely difficult for an untrained eye when we take a look at the image."]},{"metadata":{"_kg_hide-input":true,"trusted":true,"id":"tuND225OsD87","executionInfo":{"status":"aborted","timestamp":1737678325205,"user_tz":-330,"elapsed":22,"user":{"displayName":"akshat shukla","userId":"01979925258072508501"}}},"cell_type":"code","source":["fig = plt.figure(figsize=(30, 6))\n","# display 20 images\n","train_imgs = os.listdir(base_dir+\"train\")\n","for idx, img in enumerate(np.random.choice(train_imgs, 20)):\n","    ax = fig.add_subplot(2, 20//2, idx+1, xticks=[], yticks=[])\n","    im = Image.open(base_dir+\"train/\" + img)\n","    plt.imshow(im)\n","    lab = full_train_df.loc[full_train_df['id'] == img.split('.')[0], 'label'].values[0]\n","    ax.set_title('Label: %s'%lab)"],"execution_count":null,"outputs":[]},{"metadata":{"id":"Lj-CL4tQsD88"},"cell_type":"markdown","source":["# Sampling\n","Since the train dataset contains 220.025 images we can sample out a shuffled part of that, in this case 160000 samples and train on them to make predictions later."]},{"metadata":{"trusted":true,"id":"deqDek-UsD88","executionInfo":{"status":"aborted","timestamp":1737678325205,"user_tz":-330,"elapsed":22,"user":{"displayName":"akshat shukla","userId":"01979925258072508501"}}},"cell_type":"code","source":["# Number of samples in each class\n","SAMPLE_SIZE = 80000\n","\n","# Data paths\n","train_path = '../input/train/'\n","test_path = '../input/test/'\n","\n","# Use 80000 positive and negative examples\n","df_negatives = full_train_df[full_train_df['label'] == 0].sample(SAMPLE_SIZE, random_state=42)\n","df_positives = full_train_df[full_train_df['label'] == 1].sample(SAMPLE_SIZE, random_state=42)\n","\n","# Concatenate the two dfs and shuffle them up\n","train_df = sklearn.utils.shuffle(pd.concat([df_positives, df_negatives], axis=0).reset_index(drop=True))\n","\n","train_df.shape"],"execution_count":null,"outputs":[]},{"metadata":{"id":"3RuJptB6sD88"},"cell_type":"markdown","source":["# Data Pre-processing for our PyTorch\n","First we turn our data into PyTorch dataset then the data is sampled into train and validation sets. Data Augmentations are added for train data to improve performance."]},{"metadata":{"trusted":true,"id":"xIhmg7vbsD88","executionInfo":{"status":"aborted","timestamp":1737678325205,"user_tz":-330,"elapsed":22,"user":{"displayName":"akshat shukla","userId":"01979925258072508501"}}},"cell_type":"code","source":["# Our own custom class for datasets\n","class CreateDataset(Dataset):\n","    def __init__(self, df_data, data_dir = './', transform=None):\n","        super().__init__()\n","        self.df = df_data.values\n","        self.data_dir = data_dir\n","        self.transform = transform\n","\n","    def __len__(self):\n","        return len(self.df)\n","\n","    def __getitem__(self, index):\n","        img_name,label = self.df[index]\n","        img_path = os.path.join(self.data_dir, img_name+'.tif')\n","        image = cv2.imread(img_path)\n","        if self.transform is not None:\n","            image = self.transform(image)\n","        return image, label"],"execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"id":"R_gs_se9sD89","executionInfo":{"status":"aborted","timestamp":1737678325205,"user_tz":-330,"elapsed":22,"user":{"displayName":"akshat shukla","userId":"01979925258072508501"}}},"cell_type":"code","source":["transforms_train = transforms.Compose([\n","    transforms.ToPILImage(),\n","    transforms.RandomHorizontalFlip(p=0.4),\n","    transforms.RandomVerticalFlip(p=0.4),\n","    transforms.RandomRotation(20),\n","    transforms.ToTensor(),\n","    # We the get the following mean and std for the channels of all the images\n","    #transforms.Normalize((0.70244707, 0.54624322, 0.69645334), (0.23889325, 0.28209431, 0.21625058))\n","    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n","])\n","\n","train_data = CreateDataset(df_data=train_df, data_dir=train_path, transform=transforms_train)"],"execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"id":"GODnx5M_sD89","executionInfo":{"status":"aborted","timestamp":1737678325205,"user_tz":-330,"elapsed":21,"user":{"displayName":"akshat shukla","userId":"01979925258072508501"}}},"cell_type":"code","source":["# Set Batch Size\n","batch_size = 128\n","\n","# Percentage of training set to use as validation\n","valid_size = 0.1\n","\n","# obtain training indices that will be used for validation\n","num_train = len(train_data)\n","indices = list(range(num_train))\n","# np.random.shuffle(indices)\n","split = int(np.floor(valid_size * num_train))\n","train_idx, valid_idx = indices[split:], indices[:split]\n","\n","# Create Samplers\n","train_sampler = SubsetRandomSampler(train_idx)\n","valid_sampler = SubsetRandomSampler(valid_idx)\n","\n","# prepare data loaders (combine dataset and sampler)\n","train_loader = DataLoader(train_data, batch_size=batch_size, sampler=train_sampler)\n","valid_loader = DataLoader(train_data, batch_size=batch_size, sampler=valid_sampler)"],"execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"id":"Kwc5mxfysD89","colab":{"base_uri":"https://localhost:8080/","height":211},"executionInfo":{"status":"error","timestamp":1737678325205,"user_tz":-330,"elapsed":21,"user":{"displayName":"akshat shukla","userId":"01979925258072508501"}},"outputId":"3895de89-99b1-4ed4-b391-0d79c5cc401f"},"cell_type":"code","source":["transforms_test = transforms.Compose([\n","    transforms.ToPILImage(),\n","    transforms.ToTensor(),\n","    #transforms.Normalize((0.70244707, 0.54624322, 0.69645334), (0.23889325, 0.28209431, 0.21625058))\n","    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n","])\n","\n","# creating test data\n","sample_sub = pd.read_csv(\"../input/sample_submission.csv\")\n","test_data = CreateDataset(df_data=sample_sub, data_dir=test_path, transform=transforms_test)\n","\n","# prepare the test loader\n","test_loader = DataLoader(test_data, batch_size=batch_size, shuffle=False)"],"execution_count":3,"outputs":[{"output_type":"error","ename":"NameError","evalue":"name 'transforms' is not defined","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-3-63759bae5586>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m transforms_test = transforms.Compose([\n\u001b[0m\u001b[1;32m      2\u001b[0m     \u001b[0mtransforms\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mToPILImage\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mtransforms\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mToTensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0;31m#transforms.Normalize((0.70244707, 0.54624322, 0.69645334), (0.23889325, 0.28209431, 0.21625058))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mtransforms\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mNormalize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0.5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m0.5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mNameError\u001b[0m: name 'transforms' is not defined"]}]},{"metadata":{"id":"HRm22VwLsD89"},"cell_type":"markdown","source":["# Defining Model Architecture\n","I'm using a Deep Convolutional Neural Network for this task building which is fairly straight-forward in PyTorch if you understand how it works. This is one of many architectures I tried that gave better results."]},{"metadata":{"trusted":true,"id":"QXVP-7zIsD89","executionInfo":{"status":"aborted","timestamp":1737678325205,"user_tz":-330,"elapsed":20,"user":{"displayName":"akshat shukla","userId":"01979925258072508501"}}},"cell_type":"code","source":["class CNN(nn.Module):\n","    def __init__(self):\n","        super(CNN,self).__init__()\n","        # Convolutional and Pooling Layers\n","        self.conv1=nn.Sequential(\n","                nn.Conv2d(in_channels=3,out_channels=32,kernel_size=3,stride=1,padding=0),\n","                nn.BatchNorm2d(32),\n","                nn.ReLU(inplace=True),\n","                nn.MaxPool2d(2,2))\n","        self.conv2=nn.Sequential(\n","                nn.Conv2d(in_channels=32,out_channels=64,kernel_size=2,stride=1,padding=1),\n","                nn.BatchNorm2d(64),\n","                nn.ReLU(inplace=True),\n","                nn.MaxPool2d(2,2))\n","        self.conv3=nn.Sequential(\n","                nn.Conv2d(in_channels=64,out_channels=128,kernel_size=3,stride=1,padding=1),\n","                nn.BatchNorm2d(128),\n","                nn.ReLU(inplace=True),\n","                nn.MaxPool2d(2,2))\n","        self.conv4=nn.Sequential(\n","                nn.Conv2d(in_channels=128,out_channels=256,kernel_size=3,stride=1,padding=1),\n","                nn.BatchNorm2d(256),\n","                nn.ReLU(inplace=True),\n","                nn.MaxPool2d(2,2))\n","        self.conv5=nn.Sequential(\n","                nn.Conv2d(in_channels=256, out_channels=512, kernel_size=3, stride=1, padding=1),\n","                nn.BatchNorm2d(512),\n","                nn.ReLU(inplace=True),\n","                nn.MaxPool2d(2,2))\n","\n","        self.dropout2d = nn.Dropout2d()\n","\n","\n","        self.fc=nn.Sequential(\n","                nn.Linear(512*3*3,1024),\n","                nn.ReLU(inplace=True),\n","                nn.Dropout(0.4),\n","                nn.Linear(1024,512),\n","                nn.Dropout(0.4),\n","                nn.Linear(512, 1),\n","                nn.Sigmoid())\n","\n","    def forward(self,x):\n","        \"\"\"Method for Forward Prop\"\"\"\n","        x=self.conv1(x)\n","        x=self.conv2(x)\n","        x=self.conv3(x)\n","        x=self.conv4(x)\n","        x=self.conv5(x)\n","        #print(x.shape) <-- Life saving debugging step :D\n","        x=x.view(x.shape[0],-1)\n","        x=self.fc(x)\n","        return x"],"execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"id":"efaQSucosD89","executionInfo":{"status":"aborted","timestamp":1737678325205,"user_tz":-330,"elapsed":20,"user":{"displayName":"akshat shukla","userId":"01979925258072508501"}}},"cell_type":"code","source":["# check if CUDA is available\n","train_on_gpu = torch.cuda.is_available()\n","\n","if not train_on_gpu:\n","    print('CUDA is not available.  Training on CPU ...')\n","else:\n","    print('CUDA is available!  Training on GPU ...')"],"execution_count":null,"outputs":[]},{"metadata":{"id":"sXVX6WM2sD89"},"cell_type":"markdown","source":["# Training and Validation"]},{"metadata":{"trusted":true,"id":"zlIH6SsrsD89","executionInfo":{"status":"aborted","timestamp":1737678325205,"user_tz":-330,"elapsed":20,"user":{"displayName":"akshat shukla","userId":"01979925258072508501"}}},"cell_type":"code","source":["# create a complete CNN\n","model = CNN()\n","print(model)\n","\n","# Move model to GPU if available\n","if train_on_gpu: model.cuda()"],"execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"id":"0drKT7GnsD8-","executionInfo":{"status":"aborted","timestamp":1737678325205,"user_tz":-330,"elapsed":19,"user":{"displayName":"akshat shukla","userId":"01979925258072508501"}}},"cell_type":"code","source":["# Trainable Parameters\n","pytorch_total_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n","print(\"Number of trainable parameters: \\n{}\".format(pytorch_total_params))"],"execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"id":"otJkyKQasD8-","executionInfo":{"status":"aborted","timestamp":1737678325205,"user_tz":-330,"elapsed":19,"user":{"displayName":"akshat shukla","userId":"01979925258072508501"}}},"cell_type":"code","source":["# specify loss function (categorical cross-entropy loss)\n","criterion = nn.BCELoss()\n","\n","# specify optimizer\n","optimizer = optim.Adam(model.parameters(), lr=0.00015)"],"execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"id":"7I2RBOvQsD8-","executionInfo":{"status":"aborted","timestamp":1737678325205,"user_tz":-330,"elapsed":19,"user":{"displayName":"akshat shukla","userId":"01979925258072508501"}}},"cell_type":"code","source":["# number of epochs to train the model\n","n_epochs = 20\n","\n","valid_loss_min = np.Inf\n","\n","# keeping track of losses as it happen\n","train_losses = []\n","valid_losses = []\n","val_auc = []\n","test_accuracies = []\n","valid_accuracies = []\n","auc_epoch = []\n","\n","for epoch in range(1, n_epochs+1):\n","\n","    # keep track of training and validation loss\n","    train_loss = 0.0\n","    valid_loss = 0.0\n","\n","    ###################\n","    # train the model #\n","    ###################\n","    model.train()\n","    for data, target in train_loader:\n","        # move tensors to GPU if CUDA is available\n","        if train_on_gpu:\n","            data, target = data.cuda(), target.cuda().float()\n","        target = target.view(-1, 1)\n","        # clear the gradients of all optimized variables\n","        optimizer.zero_grad()\n","        # forward pass: compute predicted outputs by passing inputs to the model\n","        output = model(data)\n","        # calculate the batch loss\n","        loss = criterion(output, target)\n","        # backward pass: compute gradient of the loss with respect to model parameters\n","        loss.backward()\n","        # perform a single optimization step (parameter update)\n","        optimizer.step()\n","        # Update Train loss and accuracies\n","        train_loss += loss.item()*data.size(0)\n","\n","    ######################\n","    # validate the model #\n","    ######################\n","    model.eval()\n","    for data, target in valid_loader:\n","        # move tensors to GPU if CUDA is available\n","        if train_on_gpu:\n","            data, target = data.cuda(), target.cuda().float()\n","        # forward pass: compute predicted outputs by passing inputs to the model\n","        target = target.view(-1, 1)\n","        output = model(data)\n","        # calculate the batch loss\n","        loss = criterion(output, target)\n","        # update average validation loss\n","        valid_loss += loss.item()*data.size(0)\n","        #output = output.topk()\n","        y_actual = target.data.cpu().numpy()\n","        y_pred = output[:,-1].detach().cpu().numpy()\n","        val_auc.append(roc_auc_score(y_actual, y_pred))\n","\n","    # calculate average losses\n","    train_loss = train_loss/len(train_loader.sampler)\n","    valid_loss = valid_loss/len(valid_loader.sampler)\n","    valid_auc = np.mean(val_auc)\n","    auc_epoch.append(np.mean(val_auc))\n","    train_losses.append(train_loss)\n","    valid_losses.append(valid_loss)\n","\n","    # print training/validation statistics\n","    print('Epoch: {} | Training Loss: {:.6f} | Validation Loss: {:.6f} | Validation AUC: {:.4f}'.format(\n","        epoch, train_loss, valid_loss, valid_auc))\n","\n","    ##################\n","    # Early Stopping #\n","    ##################\n","    if valid_loss <= valid_loss_min:\n","        print('Validation loss decreased ({:.6f} --> {:.6f}).  Saving model ...'.format(\n","        valid_loss_min,\n","        valid_loss))\n","        torch.save(model.state_dict(), 'best_model.pt')\n","        valid_loss_min = valid_loss"],"execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_kg_hide-input":true,"id":"BuUo3ld8sD8-","executionInfo":{"status":"aborted","timestamp":1737678325205,"user_tz":-330,"elapsed":19,"user":{"displayName":"akshat shukla","userId":"01979925258072508501"}}},"cell_type":"code","source":["%matplotlib inline\n","%config InlineBackend.figure_format = 'retina'\n","\n","plt.plot(train_losses, label='Training loss')\n","plt.plot(valid_losses, label='Validation loss')\n","plt.xlabel(\"Epochs\")\n","plt.ylabel(\"Loss\")\n","plt.legend(frameon=False)"],"execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_kg_hide-input":true,"id":"81FPHtgcsD8-","executionInfo":{"status":"aborted","timestamp":1737678325206,"user_tz":-330,"elapsed":20,"user":{"displayName":"akshat shukla","userId":"01979925258072508501"}}},"cell_type":"code","source":["%matplotlib inline\n","%config InlineBackend.figure_format = 'retina'\n","\n","plt.plot(auc_epoch, label='Validation AUC/Epochs')\n","plt.legend(\"\")\n","plt.xlabel(\"Epochs\")\n","plt.ylabel(\"Area Under the Curve\")\n","plt.legend(frameon=False)"],"execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_kg_hide-output":true,"id":"ktj5y-UqsD8-","executionInfo":{"status":"aborted","timestamp":1737678325206,"user_tz":-330,"elapsed":20,"user":{"displayName":"akshat shukla","userId":"01979925258072508501"}}},"cell_type":"code","source":["# Load Best parameters learned from training into our model to make predictions later\n","model.load_state_dict(torch.load('best_model.pt'))"],"execution_count":null,"outputs":[]},{"metadata":{"id":"Bz1D6kumsD8-"},"cell_type":"markdown","source":["# Predictions on Test set"]},{"metadata":{"trusted":true,"id":"85N66x9ZsD8-","executionInfo":{"status":"aborted","timestamp":1737678325206,"user_tz":-330,"elapsed":19,"user":{"displayName":"akshat shukla","userId":"01979925258072508501"}}},"cell_type":"code","source":["# Turn off gradients\n","model.eval()\n","\n","preds = []\n","for batch_i, (data, target) in enumerate(test_loader):\n","    data, target = data.cuda(), target.cuda()\n","    output = model(data)\n","\n","    pr = output.detach().cpu().numpy()\n","    for i in pr:\n","        preds.append(i)\n","\n","# Create Submission file\n","sample_sub['label'] = preds"],"execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"id":"N7cSlDhusD8-","executionInfo":{"status":"aborted","timestamp":1737678325206,"user_tz":-330,"elapsed":19,"user":{"displayName":"akshat shukla","userId":"01979925258072508501"}}},"cell_type":"code","source":["for i in range(len(sample_sub)):\n","    sample_sub.label[i] = np.float(sample_sub.label[i])"],"execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"id":"Gd5aeCEosD8-","executionInfo":{"status":"aborted","timestamp":1737678325206,"user_tz":-330,"elapsed":19,"user":{"displayName":"akshat shukla","userId":"01979925258072508501"}}},"cell_type":"code","source":["sample_sub.to_csv('submission.csv', index=False)\n","sample_sub.head()"],"execution_count":null,"outputs":[]},{"metadata":{"id":"QLo7SViPsD8-"},"cell_type":"markdown","source":["# Visualizing Preditions:"]},{"metadata":{"trusted":true,"_kg_hide-input":true,"id":"FO8ctDWMsD8-","executionInfo":{"status":"aborted","timestamp":1737678325206,"user_tz":-330,"elapsed":19,"user":{"displayName":"akshat shukla","userId":"01979925258072508501"}}},"cell_type":"code","source":["def imshow(img):\n","    '''Helper function to un-normalize and display an image'''\n","    # unnormalize\n","    img = img / 2 + 0.5\n","    # convert from Tensor image and display\n","    plt.imshow(np.transpose(img, (1, 2, 0)))"],"execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_kg_hide-input":true,"id":"xSnWRDqfsD8_","colab":{"base_uri":"https://localhost:8080/","height":211},"executionInfo":{"status":"error","timestamp":1737678325206,"user_tz":-330,"elapsed":19,"user":{"displayName":"akshat shukla","userId":"01979925258072508501"}},"outputId":"7e978008-99c1-45b5-d3b2-7912816e1d92"},"cell_type":"code","source":["# obtain one batch of training images\n","dataiter = iter(test_loader)\n","images, labels = dataiter.next()\n","images = images.numpy() # convert images to numpy for display\n","\n","# plot the images in the batch, along with the corresponding labels\n","fig = plt.figure(figsize=(25, 4))\n","# display 20 images\n","for idx in np.arange(20):\n","    ax = fig.add_subplot(2, 20/2, idx+1, xticks=[], yticks=[])\n","    imshow(images[idx])\n","    prob = \"Cancer\" if(sample_sub.label[idx] >= 0.5) else \"Normal\"\n","    ax.set_title('{}'.format(prob))"],"execution_count":4,"outputs":[{"output_type":"error","ename":"NameError","evalue":"name 'test_loader' is not defined","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-4-c3b2ba19eb8b>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# obtain one batch of training images\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mdataiter\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0miter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mimages\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdataiter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mimages\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimages\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# convert images to numpy for display\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mNameError\u001b[0m: name 'test_loader' is not defined"]}]},{"metadata":{"id":"_4TmgrvJsD8_"},"cell_type":"markdown","source":["How cool is that? Now this model can be used to predict Cancer, maybe even in real-world, the AUC score I was able to achieve with this model on test set is ~0.95 which shows the model is doing way better than just guessing, it might be very much reliable if a few tweaks are to be made to take it even closer to 1.   "]},{"metadata":{"id":"1Xh9WViasD8_"},"cell_type":"markdown","source":["### Authored By,\n","[Abhinand](http://kaggle.com/abhinand05)"]}],"metadata":{"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.6.4","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"colab":{"provenance":[{"file_id":"https://storage.googleapis.com/kaggle-colab-exported-notebooks/histopathologic-cancer-detection-using-cnns-00ad209e-00f2-46b3-bb52-215b2b1928d7.ipynb?X-Goog-Algorithm=GOOG4-RSA-SHA256&X-Goog-Credential=gcp-kaggle-com%40kaggle-161607.iam.gserviceaccount.com/20250124/auto/storage/goog4_request&X-Goog-Date=20250124T002216Z&X-Goog-Expires=259200&X-Goog-SignedHeaders=host&X-Goog-Signature=343810398d9e547699588401a2b42839af5723b16fbdcf5f1ca0d8d97f75e0b783a44c238e3f77ab439f32949994352f49680d997f4f3e914bce2d092cb31e6b667a1d98ce095704208d50af8a9a01d3ecccade857a130a6e4aaef10f10d695b21986658c59360dc9762ec6c16a26b07ea8a2b20bd207b95551cc720019ef5736ab310ed4d75d5eda39bb5e3ced3f760cdb8c37a25e214329261384a420510f2a0d5fb145209880621634cf3ef848df772f8dfeb4719ddeff762ce0610224dddee817258cac29a822aeb0b8e318098f2e928f6e029ffb06e3f42bf97e014c9cd825855f9469fcefab5f1ba6b3051d8a8817088c5c9514218449186c56163f821","timestamp":1737678183186}],"gpuType":"T4"},"accelerator":"GPU"},"nbformat":4,"nbformat_minor":0}